{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Business Understanding\n",
    "\n",
    "- Understanding the Airbnb market in Chania, Greece\n",
    "- Seasonality in demand \n",
    "- Characteristics of listings with the highest price\n",
    "- Attributes that correlate with Superhosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Description of Data\n",
    "\n",
    "The data is sourced from the Inside Airbnb website http://insideairbnb.com/get-the-data.html which hosts publicly available data from the Airbnb site.\n",
    "\n",
    "- Listings:  Detailed listings data. Some of the attributes used in the analysis are price (continuous), property_type (categorical), is_superhost (categorical), neighbourhood_cleansed (categorical), ratings (continuous) among others.\n",
    "\n",
    "\n",
    "- Neighbourhoods: Includes the neighbourhood_group in Crete in both English and Greek\n",
    "    \n",
    "- Reviews:  Detailed reviews given by the guests with 6 attributes. Key attributes include date (datetime), listing_id (discrete), reviewer_id (discrete) and comment (textual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data/reviews-2.csv does not exist: 'data/reviews-2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6268b37c1fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_listings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/listings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_neighbourhoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/neighbourhoods.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/reviews-2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File data/reviews-2.csv does not exist: 'data/reviews-2.csv'"
     ]
    }
   ],
   "source": [
    "df_listings = pd.read_csv('data/listings.csv')\n",
    "df_neighbourhoods = pd.read_csv('data/neighbourhoods.csv')\n",
    "df_reviews = pd.read_csv('data/reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii) Filter in Chania, Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data with neighbourhoods in Chania (English)\n",
    "df_listings = df_listings.merge(df_neighbourhoods,left_on=\"neighbourhood_cleansed\",right_on=\"neighbourhood\")\n",
    "\n",
    "# Filter by neighbourhoods within chania\n",
    "chania_nbrhds = [\"Chania\",\"Kissamos\",\"Apokoronas\",\"Platanias\",\"Kandanos\",\"Sfakia\",\"Gaudos\"]\n",
    "df_listings = df_listings[df_listings.neighbourhood_group.isin(chania_nbrhds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Listings data\n",
    "########################\n",
    "\n",
    "# Columns to keep by category\n",
    "cols_general = ['id','neighbourhood_group','price',\n",
    "            'room_type','property_type','accommodates','instant_bookable']\n",
    "\n",
    "# cols_general = ['id','name','neighbourhood_group','latitude',\n",
    "#         'longitude','price',\n",
    "#             'bedrooms','room_type','property_type','accommodates','listing_url',\n",
    "#                 'instant_bookable']\n",
    "\n",
    "\n",
    "cols_host = [\n",
    "             'host_acceptance_rate','host_is_superhost']\n",
    "             \n",
    "\n",
    "cols_review = ['number_of_reviews','number_of_reviews_ltm',\n",
    "               'number_of_reviews_l30d','review_scores_rating',\n",
    "               'review_scores_accuracy','review_scores_cleanliness',\n",
    "               'review_scores_checkin','review_scores_communication',\n",
    "               'review_scores_location','review_scores_value',\n",
    "               'reviews_per_month']\n",
    "\n",
    "\n",
    "cols = cols_general + cols_review + cols_host\n",
    "\n",
    "\n",
    "# Start analysis with a subset of data\n",
    "df_listings = df_listings[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analysis of Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_missing_values (df_listings):\n",
    "    '''\n",
    "    Input: df with listings\n",
    "    Output: chart with missing values\n",
    "    '''\n",
    "    \n",
    "    df_na= pd.DataFrame({\"Pct_Missing\":df_listings.isnull().mean()})\n",
    "    df_na = df_na[df_na.Pct_Missing!=0]\n",
    "\n",
    "    x = list(df_na.index)\n",
    "    y = df_na.Pct_Missing*100\n",
    "    fig= go.Figure(data=go.Bar(x=x,y=y))\n",
    "    fig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n",
    "                      marker_line_width=1.5, opacity=0.6)\n",
    "    # Update Layout\n",
    "    fig.update_layout(\n",
    "        title={'text':'Missing Data',\n",
    "               'y':0.9,\n",
    "            'x':0.5,\n",
    "              'xanchor': 'center',\n",
    "                 'yanchor': 'top' },\n",
    "        xaxis=dict(\n",
    "            title='',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Percent Missing',\n",
    "             ticksuffix=\"%\"\n",
    "        ),\n",
    "\n",
    "\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "    )\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "plot_missing_values (df_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with all values missing\n",
    "\n",
    "print(\"Shape before preprocessing:\",df_listings.shape)\n",
    "df_listings = df_listings.dropna(axis=1,how=\"all\")\n",
    "\n",
    "# Remove listings that do not have any bookings or haven't received any reviews\n",
    "mask = (df_listings.host_acceptance_rate!=0) | (df_listings.reviews_per_month>0)\n",
    "df_listings = df_listings[mask]\n",
    "\n",
    "\n",
    "print(\"Shape after preprocessing:\",df_listings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For review columns it won't be accurate to impute values.\n",
    "So we will remove the rows that don't have review ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_review = ['number_of_reviews','review_scores_rating',\n",
    "               'review_scores_accuracy','review_scores_cleanliness',\n",
    "               'review_scores_checkin','review_scores_communication',\n",
    "               'review_scores_location','review_scores_value']\n",
    "\n",
    "\n",
    "# Remove rows with missing review columns \n",
    "print(\"Shape before preprocessing:\",df_listings.shape)\n",
    "df_listings = df_listings.dropna(subset=cols_review)\n",
    "\n",
    "print(\"Shape after preprocessing:\",df_listings.shape)\n",
    "plot_missing_values (df_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns to float\n",
    "cols_to_float = ['price',\"host_acceptance_rate\"]\n",
    "\n",
    "for col in cols_to_float:\n",
    "    df_listings[col] = df_listings[col].str.replace(\"$\",\"\")\n",
    "    df_listings[col] = df_listings[col].str.replace(\"%\",\"\")\n",
    "    df_listings[col] = df_listings[col].str.replace(\",\",\"\")\n",
    "    df_listings[col] = df_listings[col].astype(float)\n",
    "\n",
    "\n",
    "# Convert categorical to numeric\n",
    "df_listings['host_is_superhost'] = np.where(df_listings.host_is_superhost=='t',1,0)  \n",
    "df_listings['instant_bookable'] = np.where(df_listings.instant_bookable=='t',1,0)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data are extreme (26 listings) which are mostly due to incorrect data (we found apartments with 8000euros/night per person)\n",
    "\n",
    "To remove outliers we will calculate the price/person by using the Price of the listing divided by how many guests the listing accommodates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers by city \n",
    "\n",
    "# Find price per person\n",
    "df_listings['price_per_person'] = df_listings.price/df_listings.accommodates\n",
    "\n",
    "\n",
    "# Calculate z-score\n",
    "zscore = lambda x:(x-x.mean())/x.std()\n",
    "df_listings['price_z-score'] = df_listings.groupby(\"neighbourhood_group\")['price_per_person'].apply(zscore)\n",
    "\n",
    "# Remove everything above 4 std from the mean\n",
    "mask = df_listings['price_z-score'].abs()<4\n",
    "df_listings = df_listings[mask]\n",
    "\n",
    "print(\"Shape after preprocessing:\",df_listings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Property types distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of property types\n",
    "df_p_types = pd.DataFrame(df_listings.property_type.value_counts()/df_listings.shape[0])\n",
    "\n",
    "# Assign properties that are <4% to Other category\n",
    "threshold = 0.04\n",
    "\n",
    "# First take the properties that are >threshold to the dataframe that we will use for charting\n",
    "df_p_types_chart = df_p_types[df_p_types.property_type>=threshold]\n",
    "\n",
    "# Create Other bucket by summing all the values with <threshold\n",
    "df_other = pd.DataFrame(df_p_types.loc[df_p_types.property_type<threshold,\"property_type\"].sum(), columns=['property_type'], index=['Other'])\n",
    "\n",
    "# Add to dataframe\n",
    "df_p_types_chart= df_p_types_chart.append(df_other)\n",
    "\n",
    "# Plot using Plotly\n",
    "fig = px.pie(df_p_types_chart, values='property_type', names=df_p_types_chart.index, title='Property Types in Chania Region' ,\n",
    "             color_discrete_sequence= ['#ddbea9', '#ffe8d6', '#b7b7a4',\n",
    "                '#6b705c'])\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Rental by City "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rentals by City\n",
    "df_count_neig = pd.DataFrame(df_listings.neighbourhood_group.value_counts()/df_listings.shape[0])\n",
    "\n",
    "fig = px.pie(df_count_neig, values='neighbourhood_group', names=df_count_neig.index,color_discrete_sequence=['#ddbea9', '#ffe8d6', '#b7b7a4',\n",
    "                '#6b705c','#1d3557','#8ecae6'], title='Rentals by City')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii) Distribution of prices by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.box(df_listings,x=\"neighbourhood_group\",y=\"price_per_person\",color_discrete_sequence=['#00509d'],\n",
    "            \n",
    "             title=\"Distribution of Price per Person by City\",\n",
    "       labels=dict(neighbourhood_group=\"City\",price_per_person=\"Price/Person\"),\n",
    "       template=\"simple_white\"\n",
    "            )\n",
    "\n",
    "fig.update_layout( yaxis=dict(\n",
    "        title='Price/Person',\n",
    "         ticksuffix=\"€\"\n",
    "    ),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv) Location with highest avg rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find locations avg rating\n",
    "df_location_reviews = pd.DataFrame({\"Avg_Rating\":df_listings.groupby(\"neighbourhood_group\")['review_scores_location'].mean()})\n",
    "\n",
    "\n",
    "# Define X, Y\n",
    "x = list(df_location_reviews.index)\n",
    "y = df_location_reviews.Avg_Rating\n",
    "\n",
    "# Use plotly to plot\n",
    "fig= go.Figure(data=go.Bar(x=x,y=y,marker_color='#00509d', marker_line_color='rgb(8,48,107)',\n",
    "                  marker_line_width=1.5, opacity=0.6))\n",
    "\n",
    "# Update Layout\n",
    "fig.update_layout(\n",
    "    title={'text':'Rating by City'},\n",
    "    xaxis=dict(\n",
    "        title=''),\n",
    "    yaxis=dict(\n",
    "        title='Avg Rating',\n",
    "         ticksuffix=\"\"\n",
    "    ),\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    ")\n",
    "\n",
    "# Add hosizontall line to show the mean\n",
    "fig.add_hline(y=df_listings.review_scores_location.mean(),\n",
    "              line_width=3,line_dash=\"dash\",line_color=\"red\")\n",
    "\n",
    "# Short by highest \n",
    "fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v) Seasonality in demand\n",
    "\n",
    "To find the seasonality in demand, we will use the reviews dataset (we assume more reviews => more demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by listings available in df_listings\n",
    "unique_list_listings = list(df_listings.id.unique())\n",
    "df_reviews = df_reviews[df_reviews.listing_id.isin(unique_list_listings)]\n",
    "\n",
    "# Convert date to datetime object\n",
    "df_reviews['date'] = pd.to_datetime(df_reviews['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews by year\n",
    "df_reviews_year = df_reviews.groupby(df_reviews['date'].dt.year)[['comments']].count()\n",
    "\n",
    "# Remove 2011 and 2021 as we have incomplete data\n",
    "df_reviews_year = df_reviews_year.loc[2012:2020]\n",
    "\n",
    "# Plot\n",
    "fig = px.line(df_reviews_year, x=df_reviews_year.index, y=\"comments\", title='Popularity of Airbnb by Year',\n",
    "             template = \"simple_white\",color_discrete_sequence=['#00509d'])\n",
    "\n",
    "# Update Layout\n",
    "fig.update_layout(\n",
    "   xaxis=dict(title=''),\n",
    "    yaxis=dict(\n",
    "        title='Number of Review by Year')\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi) Seasonality by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count reviews by month and year\n",
    "df_m_y = df_reviews.groupby([df_reviews['date'].dt.month,df_reviews['date'].dt.year]).count()\n",
    "# Rename multiindex\n",
    "df_m_y.index.rename(['month','year'],inplace=True)\n",
    "\n",
    "# Find average reviews by month\n",
    "df_reviews_month = df_m_y.groupby(level=['month'])[['comments']].mean()\n",
    "\n",
    "# Rename months from numeric to categorical\n",
    "df_reviews_month = df_reviews_month.rename(index={1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',\n",
    "                              6:'Jun',7:'Jul',8:'Aug',9:'Sept',\n",
    "                              10:'Oct',11:'Nov',12:'Dec'})\n",
    "\n",
    "\n",
    "# Plot using plotly\n",
    "fig = px.line(df_reviews_month, x=df_reviews_month.index, y=\"comments\", title='Seasonality in Demand',\n",
    "             template = \"simple_white\",color_discrete_sequence=['#00509d'])\n",
    "\n",
    "# Update Layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title=''),\n",
    "    yaxis=dict(\n",
    "        title='Avg Number of Reviews across Months' )\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii) Characteristics of high-priced listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only relevant data\n",
    "data = df_listings.drop(['id','price','price_z-score'\n",
    "                     ],axis=1)\n",
    "\n",
    "\n",
    "# Define response column\n",
    "response_col = \"price_per_person\"\n",
    "\n",
    "# 1. Drop all the rows with no salaries\n",
    "data  = data.dropna(subset=[response_col], axis=0)\n",
    " \n",
    "# 2. Drop any na values as in this context we can't impute so we drop the whole column\n",
    "print(len(data))\n",
    "data = data.dropna(axis=1,how=\"any\")\n",
    "print(len(data))\n",
    "\n",
    "\n",
    "# 3. Define X,Y\n",
    "X = data.drop(response_col, axis=1)\n",
    "y = data[response_col]\n",
    "\n",
    "# 4. Create dummy columns for all the categorical variables in X, drop the original columns\n",
    "cat_df = X.select_dtypes(include=['object'])\n",
    "cat_cols = cat_df.columns\n",
    "\n",
    "for col in  cat_cols:\n",
    "    X = pd.concat([X.drop(col, axis=1), pd.get_dummies(X[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=False)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_vif_(X, thresh=6.0):\n",
    "    '''\n",
    "    Drops features that are collinear above a threashold\n",
    "    Source: https://towardsdatascience.com/how-to-remove-multicollinearity-using-python-4da8d9d8abb2\n",
    "\n",
    "    Args: \n",
    "        X: Dataframe that we want to remove\n",
    "        thresh: threshold above which drops features\n",
    "    \n",
    "    '''\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped = True\n",
    "    while dropped:\n",
    "        dropped = False\n",
    "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n",
    "               for ix in range(X.iloc[:, variables].shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X.iloc[:, variables].columns[maxloc] +\n",
    "                  '\\' at index: ' + str(maxloc))\n",
    "            del variables[maxloc]\n",
    "            dropped = True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X.iloc[:, variables]\n",
    "\n",
    "X  = calculate_vif_(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_lm_mod(X, y, cutoffs, test_size = .30, random_state=42, plot=True):\n",
    "    '''\n",
    "    INPUT\n",
    "    X - pandas dataframe, X matrix\n",
    "    y - pandas dataframe, response variable\n",
    "    cutoffs - list of ints, cutoff for number of non-zero values in dummy categorical vars\n",
    "    test_size - float between 0 and 1, default 0.3, determines the proportion of data as test data\n",
    "    random_state - int, default 42, controls random state for train_test_split\n",
    "    plot - boolean, default 0.3, True to plot result\n",
    "\n",
    "    OUTPUT\n",
    "    r2_scores_test - list of floats of r2 scores on the test data\n",
    "    r2_scores_train - list of floats of r2 scores on the train data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    '''\n",
    "    r2_scores_test, r2_scores_train, num_feats, results = [], [], [], dict()\n",
    "    for cutoff in cutoffs:\n",
    "\n",
    "        #reduce X matrix\n",
    "        reduce_X = X.iloc[:, np.where((X.sum() > cutoff) == True)[0]]\n",
    "        num_feats.append(reduce_X.shape[1])\n",
    "        #print(reduce_X.shape[1])\n",
    "\n",
    "        #split the data into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "        #fit the model and obtain pred response\n",
    "        lm_model = LinearRegression(normalize=True)\n",
    "        lm_model.fit(X_train, y_train)\n",
    "        y_test_preds = lm_model.predict(X_test)\n",
    "        y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "        #append the r2 value from the test set\n",
    "        r2_scores_test.append(r2_score(y_test, y_test_preds))\n",
    "        r2_scores_train.append(r2_score(y_train, y_train_preds))\n",
    "        results[str(cutoff)] = r2_score(y_test, y_test_preds)\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(num_feats, r2_scores_test, label=\"Test\", alpha=.5)\n",
    "        plt.plot(num_feats, r2_scores_train, label=\"Train\", alpha=.5)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('Rsquared')\n",
    "        plt.title('Rsquared by Number of Features')\n",
    "        plt.legend(loc=1)\n",
    "        plt.show()\n",
    "\n",
    "    best_cutoff = max(results, key=results.get)\n",
    "\n",
    "    #reduce X matrix\n",
    "    reduce_X = X.iloc[:, np.where((X.sum() > int(best_cutoff)) == True)[0]]\n",
    "    num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "    #split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "    #fit the model\n",
    "    lm_model = LinearRegression(normalize=True)\n",
    "    lm_model.fit(X_train, y_train)\n",
    "\n",
    "    return r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "#cutoffs here pertains to the number of missing values allowed in the used columns.\n",
    "#Therefore, lower values for the cutoff provides more predictors in the model.\n",
    "cutoffs = [5000, 3500, 2500, 1000, 100, 50, 30, 25]\n",
    "\n",
    "#Run this cell to pass your X and y to the model for testing\n",
    "r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test = find_optimal_lm_mod(X, y, cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_weights(coefficients, X_train):\n",
    "    '''\n",
    "    INPUT:\n",
    "    coefficients - the coefficients of the linear model \n",
    "    X_train - the training data, so the column names can be used\n",
    "    OUTPUT:\n",
    "    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n",
    "    \n",
    "    Provides a dataframe that can be used to understand the most influential coefficients\n",
    "    in a linear model by providing the coefficient estimates along with the name of the \n",
    "    variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    coefs_df['coefs'] = lm_model.coef_\n",
    "    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "    #coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    return coefs_df\n",
    "\n",
    "#Use the function\n",
    "coef_df = coef_weights(lm_model.coef_, X_train)\n",
    "\n",
    "#A quick look at the top results\n",
    "coef_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the 10 most significant factors\n",
    "data =  coef_df.head(10)\n",
    "\n",
    "# Rename the plot better looking\n",
    "data['est_int'] = ['Entire Villa','Room in Boutique Hotel','Chania City','Entire Cottage',\n",
    "                 'Entire Condo','Superhost','Entire Apartment','Platanias City',\n",
    "                  'Kissamos City','Sfakia city']\n",
    "\n",
    "x =data['est_int']\n",
    "y = data['coefs']\n",
    "fig= go.Figure(data=go.Bar(x=x,y=y))\n",
    "\n",
    "\n",
    "fig.update_traces(marker_color='#00509d', marker_line_color='rgb(8,48,107)',\n",
    "                  marker_line_width=1.5, opacity=0.6)\n",
    "# Update Layout\n",
    "fig.update_layout(\n",
    "    title={'text':'Most influential factors for Price/Person' },\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Model Coefficient',\n",
    "         ticksuffix=\"\"\n",
    "    ),\n",
    "\n",
    "\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    ")\n",
    "fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})\n",
    "\n",
    "text = \"Test R-squared: \" + str(np.round(100*max(r2_scores_test),2)) +\"%\"\n",
    "fig.add_annotation(x=8.5, y=20,\n",
    "            text=text,showarrow=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viii) Factors that correlate with Superhosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlations\n",
    "df_shost_corr = df_listings.corr()\n",
    "\n",
    "# Sort values by highest\n",
    "df_shost_corr[['host_is_superhost']].sort_values(by=\"host_is_superhost\",ascending=False)\n",
    "\n",
    "# Lets clean it a little bit (too many factors of the same characteristic)\n",
    "\n",
    "# Dropping duplications or uneccessary\n",
    "df_shost_corr = df_shost_corr.drop(['host_is_superhost','number_of_reviews_l30d','number_of_reviews',\n",
    "                   'reviews_per_month','price_z-score','price','id'])\n",
    "\n",
    "# Sort Values\n",
    "df_shost_corr[['host_is_superhost']].sort_values(by=\"host_is_superhost\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 10 factors\n",
    "df_superhost = df_shost_corr[['host_is_superhost']].sort_values(by=\"host_is_superhost\",ascending=False).head(10)\n",
    "\n",
    "# Rename them\n",
    "df_superhost.index = ['Number of Reviews (LTM)','Response Rate',\n",
    "                                     'Review Scores Rating','Acceptance Rate','Instant Bookable',\n",
    "                     'Review Score Cleanliness','Review Score Accuracy','Review Score Value',\n",
    "                      'Review Score Communication',\n",
    "                      'Price/Person']\n",
    "\n",
    "# Plot them using plotly\n",
    "x =df_superhost.index\n",
    "y = df_superhost['host_is_superhost']\n",
    "fig= go.Figure(data=go.Bar(x=x,y=y))\n",
    "\n",
    "fig.update_traces(marker_color='#c70505', marker_line_color='rgb(8,48,107)',\n",
    "                  marker_line_width=1.5, opacity=0.6)\n",
    "# Update Layout\n",
    "fig.update_layout(\n",
    "    title={'text':'Attributes correlated to Superhosts' },\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Correlation',\n",
    "         ticksuffix=\"\"\n",
    "    ),\n",
    "\n",
    "\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    ")\n",
    "fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
